{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates special bib files using Scholarly to be imported into Zotero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ScraperAPI to load all trunc results from JSON, write to bib file\n",
    "# \tInclude URL, gsc ID. (Coding required)\n",
    "# \t'url_scholarbib' field will need to be copied to 'extra' field for zotero import\n",
    "\n",
    "# Steps.\n",
    "# 1. Load JSON file into array.\n",
    "# 2. Write the array into a search scholar iterator object.\n",
    "# 3. Generate the bib from only the fields provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file as json object here.\n",
    "\n",
    "import json\n",
    "\n",
    "# jsonfilename = '197hierarchy_i_mean_pub_without_fill.json' # last one\n",
    "# jsonfilename = '116hierarchical_refers2019_pub_without_fill.json'\n",
    "# jsonfilename = '15hierarchical_refers2022_pub_without_fill.json'\n",
    "# jsonfilename = '88hierarchy_we_mean_pub_without_fill.json' # skipped this one accidentally\n",
    "# jsonfilename = '823hierarchy_meaning2019_pub_without_fill.json'\n",
    "# jsonfilename = '189hierarchy_meaning2022_pub_without_fill.json'\n",
    "# jsonfilename = '249defines_hierarchy2019_pub_without_fill.json'\n",
    "# jsonfilename = '35defines_hierarchy2022_pub_without_fill.json'\n",
    "# jsonfilename = '189defines_hierarchical2022_pub_without_fill.json'\n",
    "# jsonfilename = '30defines_hierarchical2022_pub_without_fill.json' # should be 2019\n",
    "# jsonfilename = '299hierarchy_refers2022_pub_without_fill.json'\n",
    "# jsonfilename = '461hierarchy_refers2019_pub_without_fill.json' # After this (up) I used new process to make json files\n",
    "# jsonfilename = '570hierarchy_refers2015_pub_without_fill.json'\n",
    "# jsonfilename = '697hierarchy_refers2009_pub_without_fill.json'\n",
    "# jsonfilename = '536hierarchy_meaning2015_pub_without_fill.json'\n",
    "# jsonfilename = '181hierarchy_defined2009_pub_without_fill.json'\n",
    "# jsonfilename = '959hierarchy_defined2007_pub_without_fill.json'\n",
    "# jsonfilename = '379hierarchy_defined2022_pub_without_fill.json'\n",
    "# jsonfilename = '577hierarchy_defined2019_pub_without_fill.json'\n",
    "# jsonfilename = '774hierarchy_defined2015_pub_without_fill.json'\n",
    "# jsonfilename = '1160hierarchy_defined2009_pub_without_fill.json'\n",
    "# jsonfilename = '22hierarchical_i_mean_pub_without_fill.json'\n",
    "jsonfilename = '928hierarchical_definition_pub_without_fill.json'\n",
    "# jsonfilename = '223definition_hierarchical_pub_without_fill.json'\n",
    "# jsonfilename = '37definition_for_hierarchical_pub_without_fill.json'\n",
    "# jsonfilename = '795hierarchical_meaning_pub_without_fill.json'\n",
    "# jsonfilename = '5_hierarchical_they_mean_pub_without_fill.json'\n",
    "# jsonfilename = '636definition_of_hierarchical_pub_without_fill.json'\n",
    "# jsonfilename = '31hierarchical_we_mean_pub_without_fill.json'\n",
    "# jsonfilename = '650define_hierarchical_pub_without_fill.json'\n",
    "# jsonfilename = '49hierarchical_defined_pub_without_fill.json'\n",
    "# jsonfilename = '2860hierarchy_defined_pub_without_fill.json'\n",
    "# jsonfilename = '680definition_of_hierarchy_pub_without_fill.json'\n",
    "# jsonfilename = '411hierarchy_definition_pub_without_fill.json'\n",
    "# jsonfilename = '1010hierarchy_meaning_pub_without_fill.json'\n",
    "# jsonfilename = '247defining_hierarchy_pub_without_fill.json'\n",
    "# jsonfilename = '243definition_hierarchy_pub_without_fill.json'\n",
    "# jsonfilename = '1definition_for_hierarchy_pub_without_fill.json'\n",
    "# jsonfilename = '228hierarchy_it_means_pub_without_fill.json'\n",
    "# jsonfilename = '4hierarchy_they_mean_pub_without_fill.json'\n",
    "# jsonfilename = '472define_hierarchy_pub_without_fill.json'\n",
    "# jsonfilename = '378define_hierarchy_pub_without_fill.json' # the real file\n",
    "# jsonfilename = '3entry_test.json' # didn't even name this right, it's 2 entry\n",
    "# started with the entry above, each new one is above the previous\n",
    "\n",
    "json_array = []\n",
    "\n",
    "with open(jsonfilename, 'r') as filehandle:\n",
    "    bigstring = filehandle.read()\n",
    "    bigstring = bigstring.replace(\"}{\",\"}\\n{\")\n",
    "    # print('type is ' + str(type(bigstring.splitlines())))\n",
    "\n",
    "    for i in bigstring.splitlines():\n",
    "        json_line = json.loads(i)\n",
    "        json_array.append(json_line)\n",
    "\n",
    "        # print(\"Decoded JSON Data From File\")\n",
    "        # for key, value in json_line.items():\n",
    "        #     print(key, \":\", value)\n",
    "        # print(\"Done reading json file\")\n",
    "        \n",
    "    # print('Priting test_array...')\n",
    "    # print(test_array)\n",
    "    # print(type(test_array))\n",
    "    # print(len(test_array))\n",
    "\n",
    "# Compare what my array looks like compared to the scholarly array.\n",
    "# Looks good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bibtexparser.bwriter import BibTexWriter\n",
    "from bibtexparser.bibdatabase import BibDatabase\n",
    "\n",
    "db = BibDatabase()\n",
    "# # example:\n",
    "# db.entries = [\n",
    "#     {'journal': 'Nice Journal',\n",
    "#      'comments': 'A comment',\n",
    "#      'pages': '12--23',\n",
    "#      'month': 'jan',\n",
    "#      'abstract': 'This is an abstract. This line should be long enough to test\\nmultilines...',\n",
    "#      'title': 'An amazing title',\n",
    "#      'year': '2013',\n",
    "#      'volume': '12',\n",
    "#      'ID': 'Cesar2013',\n",
    "#      'author': 'Jean César',\n",
    "#      'keyword': 'keyword1, keyword2',\n",
    "#      'ENTRYTYPE': 'article'}]\n",
    "\n",
    "# Now we write the test_array to the entries\n",
    "# bib : \n",
    "# {'title': 'The fluency of social hierarchy: the ease with which hierarchical relationships are seen, remembered, learned, and liked.', \n",
    "# 'author': ['EM Zitek', 'LZ Tiedens'], \n",
    "# 'year': '2012', \n",
    "# 'venue': 'Journal of personality and social …', \n",
    "# 'abstract': 'This pre-test illustrates that regardless of how our participants define'\n",
    "\n",
    "        # db.entries = [\n",
    "        #     {'journal': None,\n",
    "        #      'comments': None,\n",
    "        #      'pages': None,\n",
    "        #      'month': None,\n",
    "        #      'abstract': pub_item['bib']['abstract'],\n",
    "        #      'title': pub_item['bib']['title'],\n",
    "        #      'year': pub_item['bib']['year'],\n",
    "        #      'volume': None,\n",
    "        #      'ID': None,\n",
    "        #      'author': pub_item['bib']['author'],\n",
    "        #      'keyword': None,\n",
    "        #      'url': pub_item['pub_url'],\n",
    "        #      'extra': pub_item['url_scholarbib'],\n",
    "        #      'ENTRYTYPE': None}]\n",
    "\n",
    "        # From non-filled bibs, scholarly doesn't know the ENTRYTYPE, which may come from pub_type, \n",
    "        # which comes from who the hell knows where. I cannot figure out how scholarly gets that \n",
    "        # info, i.e., whether it's a book or article. Completely hidden.\n",
    "        # Wait, I know where it comes from.\n",
    "        # It comes from the GS bibtex when you click the bibtex link.\n",
    "        # That's why it's not there until scholarly calls filled.\n",
    "\n",
    "        # We'll just make all bib entries ENTRYTYPE 'article'.\n",
    "        # ID, in the GS convention, is \n",
    "        # authorYEARtitle1stword, e.g., pelinovsky1998rational\n",
    "        # author should be in the format \n",
    "        # author = {Adkins, Lisa and Cooper, Melinda and Konings, Martijn},\n",
    "\n",
    "filename_stub = jsonfilename.split('.')[0]\n",
    "bibfile_name = filename_stub + '_bib.bib'\n",
    "\n",
    "def last_first_authors(author_array):\n",
    "     # print(author_array) # for testing\n",
    "    lf_author = ''\n",
    "    person_counter = 1\n",
    "    auth_list = author_array\n",
    "    len_auth_list = len(auth_list)\n",
    "    for person in auth_list:\n",
    "        # check for condition where there is no first name or initial:\n",
    "        # e.g., [\"S Nagar\", \"Nagar\", \"Anglin\"]\n",
    "        if ' ' in person:\n",
    "            lf_author = lf_author + person.split()[1] + ', ' + person.split()[0]\n",
    "        else: \n",
    "            lf_author = lf_author + person\n",
    "        if person_counter < len_auth_list:\n",
    "            lf_author = str(lf_author + ' and ')\n",
    "        person_counter += 1\n",
    "    return lf_author\n",
    "\n",
    "writer = BibTexWriter()\n",
    "with open(bibfile_name, 'w', encoding='utf-8') as bibfile:\n",
    "    for pub_item in json_array:\n",
    "        # print(pub_item['gsrank']) # for testing\n",
    "        first_word = pub_item['bib']['title'].split()[0]\n",
    "        # issue here with Korean unicode because there may not be a space to split on\n",
    "        if not pub_item['bib']['author']: # may be an empty array or string\n",
    "            lastname_firstauthor = 'noauthor' \n",
    "            print(\"Author name was empty string\")\n",
    "        elif ' ' in pub_item['bib']['author'][0]:\n",
    "            lastname_firstauthor = pub_item['bib']['author'][0].split()[1]\n",
    "        else:                             # may be name without space\n",
    "            lastname_firstauthor = pub_item['bib']['author'][0]\n",
    "        auth_reformatted = str(last_first_authors(pub_item['bib']['author']))\n",
    "        id_str = str(lastname_firstauthor + \n",
    "                       str(pub_item['bib']['year']) + \n",
    "                       first_word).lower()\n",
    "        db.entries = [\n",
    "            {'abstract': pub_item['bib']['abstract'],\n",
    "             'title': pub_item['bib']['title'],\n",
    "             'year': pub_item['bib']['year'],\n",
    "             'author': auth_reformatted,\n",
    "             'url': pub_item['pub_url'],\n",
    "             'extra': pub_item['url_scholarbib'],\n",
    "             'ENTRYTYPE': 'article',\n",
    "             'ID': id_str}]\n",
    "        # print(db.entries)\n",
    "        bibfile.write(writer.write(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is testing code for the bibtext builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "print(len(json_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was just for listing the names of the bib files,\n",
    "# so I could easily put them in excel and compare terms.\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "pattern=\"\\d+\"\n",
    "\n",
    "for ipath in os.listdir():\n",
    "    if 'bib.bib' in ipath:\n",
    "        prefix = 'hierarchical'\n",
    "        if 'hierarchy' in ipath:\n",
    "            prefix = 'hierarchy'\n",
    "        no_num = ipath.lstrip('0123456789.- ')\n",
    "        print(prefix + '\\t' + no_num + '\\t' + ipath)\n",
    "        if 'i_mean' in ipath:\n",
    "            print('NEW ONE: ' + ipath)\n",
    "\n",
    "# TODO: Use the code below to extract the first number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "pattern=\"\\d+\"\n",
    "\n",
    "for ipath in os.listdir():\n",
    "    if 'bib.bib' in ipath:\n",
    "        str_list=re.findall(pattern,ipath)\n",
    "        num_first = str_list[0]\n",
    "        prefix = 'hierarchical'\n",
    "        if 'hierarchy' in ipath:\n",
    "            prefix = 'hierarchy'\n",
    "        print(prefix + '\\t' + num_first + '\\t' + ipath)       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty string\n",
      "somelongstring\n"
     ]
    }
   ],
   "source": [
    "# dissection of \n",
    "# lastname_firstauthor = pub_item['bib']['author'][0].split()[1]\n",
    "\n",
    "emptyfoo = ''\n",
    "foo = 'somelongstring'\n",
    "hangul_foo = '\\uc774\\uacbd\\uc544'\n",
    "\n",
    "# for i in foo.split():\n",
    "#     print(i)\n",
    "\n",
    "if not emptyfoo:\n",
    "    print('empty string')\n",
    "\n",
    "print(foo.split()[0])\n",
    "\n",
    "# if ' ' in pub_item['bib']['author'][0]:\n",
    "#     lastname_firstauthor = pub_item['bib']['author'][0].split()[1]\n",
    "# else:\n",
    "#     lastname_firstauthor = pub_item['bib']['author'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S Nagar\n",
      "true\n",
      "Nagar\n",
      "false\n",
      "Anglin\n",
      "false\n",
      "['S Nagar', 'Nagar', 'Anglin']\n",
      "S Nagar\n",
      "True.\n",
      "Nagar\n",
      "False.\n",
      "Anglin\n",
      "False.\n",
      "Nagar, S and Nagar and Anglin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# str.find(substring, startPos, StopPos)\n",
    "test_array = [\"S Nagar\", \"Nagar\", \"Anglin\"]\n",
    "\n",
    "def last_first_authors(test_array):\n",
    "    print(test_array)\n",
    "    lf_author = ''\n",
    "    person_counter = 1\n",
    "    auth_list = test_array\n",
    "    len_auth_list = len(auth_list)\n",
    "    for person in auth_list:\n",
    "        # check for condition where there is no first name or initial:\n",
    "        # e.g., [\"S Nagar\", \"Nagar\", \"Anglin\"]\n",
    "        if ' ' in person:\n",
    "            lf_author = lf_author + person.split()[1] + ', ' + person.split()[0]\n",
    "        else: \n",
    "            lf_author = lf_author + person\n",
    "        if person_counter < len_auth_list:\n",
    "            lf_author = str(lf_author + ' and ')\n",
    "        person_counter += 1\n",
    "    return lf_author\n",
    "\n",
    "print(last_first_authors(test_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3entry_test_bib.bib\n"
     ]
    }
   ],
   "source": [
    "jsonfilename = '3entry_test.json' \n",
    "filename_stub = jsonfilename.split('.')[0]\n",
    "bibfile_name = filename_stub + '_bib.bib'\n",
    "print(bibfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bibtexparser.bwriter import BibTexWriter\n",
    "from bibtexparser.bibdatabase import BibDatabase\n",
    "\n",
    "db = BibDatabase()\n",
    "db.entries = [\n",
    "    {'journal': 'Nice Journal',\n",
    "     'comments': 'A comment',\n",
    "     'pages': '12--23',\n",
    "     'month': 'jan',\n",
    "     'abstract': 'This is an abstract. This line should be long enough to test\\nmultilines...',\n",
    "     'title': 'An amazing title',\n",
    "     'year': '2013',\n",
    "     'volume': '12',\n",
    "     'ID': 'Cesar2013',\n",
    "     'author': 'Jean César',\n",
    "     'keyword': 'keyword1, keyword2',\n",
    "     'ENTRYTYPE': 'article'}]\n",
    "\n",
    "writer = BibTexWriter()\n",
    "with open('basic_bib_test.bib', 'w') as bibfile:\n",
    "    bibfile.write(writer.write(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_array[0]['bib']['title'])\n",
    "# print(test_array[0]['bib']['author'])\n",
    "# print(test_array[0]['bib']['author'][0].split()[1])\n",
    "print(len(test_array[0]['bib']['author']))\n",
    "lf_author = ''\n",
    "person_counter = 1\n",
    "auth_list = test_array[0]['bib']['author']\n",
    "len_auth_list = len(auth_list)\n",
    "print(person_counter)\n",
    "for person in auth_list:\n",
    "    lf_author = lf_author + person.split()[1] + ', ' + person.split()[0]\n",
    "    if person_counter < len_auth_list:\n",
    "        print('activated if')\n",
    "        lf_author = str(lf_author + ' and ')\n",
    "    person_counter += 1\n",
    "print(lf_author)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I must load the JSON file and make it into a searchscholariterator object.\n",
    "# But maybe I don't have to...?\n",
    "\n",
    "def make_iterator_obj():\n",
    "    print('Making an iterator object here.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type is <class 'list'>\n",
      "Decoded JSON Data From File\n",
      "container_type : Publication\n",
      "source : PUBLICATION_SEARCH_SNIPPET\n",
      "bib : {'title': 'The fluency of social hierarchy: the ease with which hierarchical relationships are seen, remembered, learned, and liked.', 'author': ['EM Zitek', 'LZ Tiedens'], 'year': '2012', 'venue': 'Journal of personality and social …', 'abstract': 'This pre-test illustrates that regardless of how our participants define hierarchy, and whether  they see it as more about status or power, they, as intended, perceived one of the diagrams'}\n",
      "filled : False\n",
      "gsrank : 2\n",
      "pub_url : https://psycnet.apa.org/journals/psp/102/1/98/\n",
      "author_id : ['xTro5rgAAAAJ', '']\n",
      "url_scholarbib : /scholar?hl=en&num=20&q=info:BU8LqlCRAtYJ:scholar.google.com/&output=cite&scirp=1&hl=en\n",
      "url_add_sclib : /citations?hl=en&num=20&xsrf=&continue=/scholar%3Fq%3Dsocial%2BAND%2B%2522define%2Bhierarchy%2522%2B-%2522analytic%2Bhierarchy%2Bprocess%2522%2B-%2522analytical%2Bhierarchy%2Bprocess%2522%2B-%2522response%2Bhierarchy%2522%2B-%2522polynomial-time%2Bhierarchy%2522%2B-%2522polynomial%2Bhierarchy%2522%2B-%2522gauge%2Bhierarchy%2522%2B-%2522geometric%2Bhierarchy%2522%2B-%2522hierarchy%2Bof%2Bneeds%2522%2B-%2522hierarchy%2Bof%2Beffects%2522%2B-%26hl%3Den%26num%3D20%26as_sdt%3D1,33%26as_vis%3D1&citilm=1&update_op=library_add&info=BU8LqlCRAtYJ&ei=qz3DYtC0LMiUywS7m6SYCg&json=\n",
      "num_citations : 234\n",
      "citedby_url : /scholar?cites=15421047849706278661&as_sdt=5,33&sciodt=1,33&hl=en&num=20\n",
      "url_related_articles : /scholar?q=related:BU8LqlCRAtYJ:scholar.google.com/&scioq=social+AND+%22define+hierarchy%22+AND+-%22analytic+hierarchy+process%22+AND+-%22analytical+hierarchy+process%22+AND+-%22response+hierarchy%22+AND+-%22polynomial-time+hierarchy%22+AND+-%22polynomial+hierarchy%22+AND+-%22gauge+hierarchy%22+AND+-%22geometric+hierarchy%22+AND+-%22hierarchy+of+&hl=en&num=20&as_sdt=1,33&as_vis=1\n",
      "eprint_url : https://www.researchgate.net/profile/Emily-Zitek/publication/51631120_The_Fluency_of_Social_Hierarchy_The_Ease_With_Which_Hierarchical_Relationships_Are_Seen_Remembered_Learned_and_Liked/links/5b2a82e14585150c6341f24c/The-Fluency-of-Social-Hierarchy-The-Ease-With-Which-Hierarchical-Relationships-Are-Seen-Remembered-Learned-and-Liked.pdf\n",
      "Done reading json file\n",
      "Decoded JSON Data From File\n",
      "container_type : Publication\n",
      "source : PUBLICATION_SEARCH_SNIPPET\n",
      "bib : {'title': 'Social centrality using network hierarchy and community structure', 'author': ['R Saxena', 'S Kaur', 'V Bhatnagar'], 'year': '2018', 'venue': 'Data Mining and Knowledge Discovery', 'abstract': 'This permits us to use node trussness as property to define hierarchy levels in the network.  Given a graph decomposition, each hierarchy level in the graph is composed of all vertices'}\n",
      "filled : False\n",
      "gsrank : 3\n",
      "pub_url : https://link.springer.com/article/10.1007/s10618-018-0582-x\n",
      "author_id : ['_RvfyjEAAAAJ', 'sDEcSS8AAAAJ', 'IlgiE24AAAAJ']\n",
      "url_scholarbib : /scholar?hl=en&num=20&q=info:b67ZCQLqCrkJ:scholar.google.com/&output=cite&scirp=2&hl=en\n",
      "url_add_sclib : /citations?hl=en&num=20&xsrf=&continue=/scholar%3Fq%3Dsocial%2BAND%2B%2522define%2Bhierarchy%2522%2B-%2522analytic%2Bhierarchy%2Bprocess%2522%2B-%2522analytical%2Bhierarchy%2Bprocess%2522%2B-%2522response%2Bhierarchy%2522%2B-%2522polynomial-time%2Bhierarchy%2522%2B-%2522polynomial%2Bhierarchy%2522%2B-%2522gauge%2Bhierarchy%2522%2B-%2522geometric%2Bhierarchy%2522%2B-%2522hierarchy%2Bof%2Bneeds%2522%2B-%2522hierarchy%2Bof%2Beffects%2522%2B-%26hl%3Den%26num%3D20%26as_sdt%3D1,33%26as_vis%3D1&citilm=1&update_op=library_add&info=b67ZCQLqCrkJ&ei=qz3DYtC0LMiUywS7m6SYCg&json=\n",
      "num_citations : 13\n",
      "citedby_url : /scholar?cites=13333726941259869807&as_sdt=5,33&sciodt=1,33&hl=en&num=20\n",
      "url_related_articles : /scholar?q=related:b67ZCQLqCrkJ:scholar.google.com/&scioq=social+AND+%22define+hierarchy%22+AND+-%22analytic+hierarchy+process%22+AND+-%22analytical+hierarchy+process%22+AND+-%22response+hierarchy%22+AND+-%22polynomial-time+hierarchy%22+AND+-%22polynomial+hierarchy%22+AND+-%22gauge+hierarchy%22+AND+-%22geometric+hierarchy%22+AND+-%22hierarchy+of+&hl=en&num=20&as_sdt=1,33&as_vis=1\n",
      "eprint_url : https://arxiv.org/pdf/1806.08964\n",
      "Done reading json file\n",
      "Priting test_array...\n",
      "['{\"container_type\": \"Publication\", \"source\": \"PUBLICATION_SEARCH_SNIPPET\", \"bib\": {\"title\": \"The fluency of social hierarchy: the ease with which hierarchical relationships are seen, remembered, learned, and liked.\", \"author\": [\"EM Zitek\", \"LZ Tiedens\"], \"year\": \"2012\", \"venue\": \"Journal of personality and social \\\\u2026\", \"abstract\": \"This pre-test illustrates that regardless of how our participants define hierarchy, and whether  they see it as more about status or power, they, as intended, perceived one of the diagrams\"}, \"filled\": false, \"gsrank\": 2, \"pub_url\": \"https://psycnet.apa.org/journals/psp/102/1/98/\", \"author_id\": [\"xTro5rgAAAAJ\", \"\"], \"url_scholarbib\": \"/scholar?hl=en&num=20&q=info:BU8LqlCRAtYJ:scholar.google.com/&output=cite&scirp=1&hl=en\", \"url_add_sclib\": \"/citations?hl=en&num=20&xsrf=&continue=/scholar%3Fq%3Dsocial%2BAND%2B%2522define%2Bhierarchy%2522%2B-%2522analytic%2Bhierarchy%2Bprocess%2522%2B-%2522analytical%2Bhierarchy%2Bprocess%2522%2B-%2522response%2Bhierarchy%2522%2B-%2522polynomial-time%2Bhierarchy%2522%2B-%2522polynomial%2Bhierarchy%2522%2B-%2522gauge%2Bhierarchy%2522%2B-%2522geometric%2Bhierarchy%2522%2B-%2522hierarchy%2Bof%2Bneeds%2522%2B-%2522hierarchy%2Bof%2Beffects%2522%2B-%26hl%3Den%26num%3D20%26as_sdt%3D1,33%26as_vis%3D1&citilm=1&update_op=library_add&info=BU8LqlCRAtYJ&ei=qz3DYtC0LMiUywS7m6SYCg&json=\", \"num_citations\": 234, \"citedby_url\": \"/scholar?cites=15421047849706278661&as_sdt=5,33&sciodt=1,33&hl=en&num=20\", \"url_related_articles\": \"/scholar?q=related:BU8LqlCRAtYJ:scholar.google.com/&scioq=social+AND+%22define+hierarchy%22+AND+-%22analytic+hierarchy+process%22+AND+-%22analytical+hierarchy+process%22+AND+-%22response+hierarchy%22+AND+-%22polynomial-time+hierarchy%22+AND+-%22polynomial+hierarchy%22+AND+-%22gauge+hierarchy%22+AND+-%22geometric+hierarchy%22+AND+-%22hierarchy+of+&hl=en&num=20&as_sdt=1,33&as_vis=1\", \"eprint_url\": \"https://www.researchgate.net/profile/Emily-Zitek/publication/51631120_The_Fluency_of_Social_Hierarchy_The_Ease_With_Which_Hierarchical_Relationships_Are_Seen_Remembered_Learned_and_Liked/links/5b2a82e14585150c6341f24c/The-Fluency-of-Social-Hierarchy-The-Ease-With-Which-Hierarchical-Relationships-Are-Seen-Remembered-Learned-and-Liked.pdf\"}', '{\"container_type\": \"Publication\", \"source\": \"PUBLICATION_SEARCH_SNIPPET\", \"bib\": {\"title\": \"Social centrality using network hierarchy and community structure\", \"author\": [\"R Saxena\", \"S Kaur\", \"V Bhatnagar\"], \"year\": \"2018\", \"venue\": \"Data Mining and Knowledge Discovery\", \"abstract\": \"This permits us to use node trussness as property to define hierarchy levels in the network.  Given a graph decomposition, each hierarchy level in the graph is composed of all vertices\"}, \"filled\": false, \"gsrank\": 3, \"pub_url\": \"https://link.springer.com/article/10.1007/s10618-018-0582-x\", \"author_id\": [\"_RvfyjEAAAAJ\", \"sDEcSS8AAAAJ\", \"IlgiE24AAAAJ\"], \"url_scholarbib\": \"/scholar?hl=en&num=20&q=info:b67ZCQLqCrkJ:scholar.google.com/&output=cite&scirp=2&hl=en\", \"url_add_sclib\": \"/citations?hl=en&num=20&xsrf=&continue=/scholar%3Fq%3Dsocial%2BAND%2B%2522define%2Bhierarchy%2522%2B-%2522analytic%2Bhierarchy%2Bprocess%2522%2B-%2522analytical%2Bhierarchy%2Bprocess%2522%2B-%2522response%2Bhierarchy%2522%2B-%2522polynomial-time%2Bhierarchy%2522%2B-%2522polynomial%2Bhierarchy%2522%2B-%2522gauge%2Bhierarchy%2522%2B-%2522geometric%2Bhierarchy%2522%2B-%2522hierarchy%2Bof%2Bneeds%2522%2B-%2522hierarchy%2Bof%2Beffects%2522%2B-%26hl%3Den%26num%3D20%26as_sdt%3D1,33%26as_vis%3D1&citilm=1&update_op=library_add&info=b67ZCQLqCrkJ&ei=qz3DYtC0LMiUywS7m6SYCg&json=\", \"num_citations\": 13, \"citedby_url\": \"/scholar?cites=13333726941259869807&as_sdt=5,33&sciodt=1,33&hl=en&num=20\", \"url_related_articles\": \"/scholar?q=related:b67ZCQLqCrkJ:scholar.google.com/&scioq=social+AND+%22define+hierarchy%22+AND+-%22analytic+hierarchy+process%22+AND+-%22analytical+hierarchy+process%22+AND+-%22response+hierarchy%22+AND+-%22polynomial-time+hierarchy%22+AND+-%22polynomial+hierarchy%22+AND+-%22gauge+hierarchy%22+AND+-%22geometric+hierarchy%22+AND+-%22hierarchy+of+&hl=en&num=20&as_sdt=1,33&as_vis=1\", \"eprint_url\": \"https://arxiv.org/pdf/1806.08964\"}']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# How stack says to do it:\n",
    "\n",
    "# from types import SimpleNamespace\n",
    "\n",
    "# data = '{\"name\": \"John Smith\", \"hometown\": {\"name\": \"New York\", \"id\": 123}}'\n",
    "\n",
    "# # Parse JSON into an object with attributes corresponding to dict keys.\n",
    "# x = json.loads(data, object_hook=lambda d: SimpleNamespace(**d))\n",
    "# print(x.name, x.hometown.name, x.hometown.id)\n",
    "\n",
    "# call the make_iterator_obj with json object as argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the code attempting to get the scholarly library working to write the bib\n",
    "The bibtex function is such a mess that it wasn't feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste in and modify all the necessary functions from Scholarly here\n",
    "\n",
    "import sys\n",
    "from enum import Enum\n",
    "from typing import List, Dict\n",
    "if sys.version_info >= (3, 8):\n",
    "    from typing import TypedDict\n",
    "else:\n",
    "    from typing_extensions import TypedDict\n",
    "import bibtexparser\n",
    "from bibtexparser.bibdatabase import BibDatabase\n",
    "\n",
    "CitesPerYear = Dict[int, int]\n",
    "\n",
    "_BIB_MAPPING = {\n",
    "    'ENTRYTYPE': 'pub_type',\n",
    "    'ID': 'bib_id',\n",
    "}\n",
    "\n",
    "_BIB_DATATYPES = {\n",
    "    'number': 'str',\n",
    "    'volume': 'str',\n",
    "}\n",
    "_BIB_REVERSE_MAPPING = {\n",
    "    'pub_type': 'ENTRYTYPE',\n",
    "    'bib_id': 'ID',\n",
    "    'pub_url' : 'url',\n",
    "    'url_scholarbib' : 'extra'\n",
    "}\n",
    "\n",
    "class PublicationSource(str, Enum):\n",
    "    '''\n",
    "    Defines the source of the publication. In general, a publication\n",
    "    on Google Scholar has two forms:\n",
    "    * Appearing as a PUBLICATION SNIPPET and\n",
    "    * Appearing as a paper in an AUTHOR PAGE\n",
    "    '''\n",
    "    PUBLICATION_SEARCH_SNIPPET = \"PUBLICATION_SEARCH_SNIPPET\"\n",
    "    AUTHOR_PUBLICATION_ENTRY = \"AUTHOR_PUBLICATION_ENTRY\"\n",
    "    JOURNAL_CITATION_LIST = \"JOURNAL_CITATION_LIST\"\n",
    "\n",
    "class Mandate(TypedDict, total=False):\n",
    "    \"\"\"\n",
    "    :class:`Mandate <Mandate>` A funding mandate for a given year\n",
    "    :param agency: name of the funding agency\n",
    "    :param url_policy: url of the policy for this mandate\n",
    "    :param url_policy_cached: url of the policy cached by Google Scholar\n",
    "    :param effective_date: date from which the policy is effective\n",
    "    :param embargo: period within which the article must be publicly available\n",
    "    :param acknowledgement: text in the paper acknowledging the funding\n",
    "    :param grant: grant ID that supported this work\n",
    "    \"\"\"\n",
    "    agency: str\n",
    "    url_policy: str\n",
    "    url_policy_cached: str\n",
    "    effective_date: str\n",
    "    embargo: str\n",
    "    acknowledgement: str\n",
    "    grant: str\n",
    "\n",
    "class BibEntry(TypedDict, total=False):\n",
    "    \"\"\"\n",
    "    :class:`BibEntry <BibEntry>` The bibliographic entry for a publication\n",
    "            (When source is not specified, the field is present in all sources)\n",
    "    :param pub_type: the type of entry for this bib (for example 'article') (source: PUBLICATION_SEARCH_SNIPPET)\n",
    "    :param bib_id: bib entry id (source: PUBLICATION_SEARCH_SNIPPET)\n",
    "    :param abstract: description of the publication\n",
    "    :param title: title of the publication\n",
    "    :param author: list of author the author names that contributed to this publication\n",
    "    :param pub_year: the year the publication was first published\n",
    "    :param venue: the venue of the publication (source: PUBLICATION_SEARCH_SNIPPET)\n",
    "    :param journal: Journal Name\n",
    "    :param volume: number of years a publication has been circulated\n",
    "    :param number: NA number of a publication\n",
    "    :param pages: range of pages\n",
    "    :param publisher: The publisher's name\n",
    "    :param citation: Formatted citation string, usually containing journal name, volume and page numbers (source: AUTHOR_PUBLICATION_ENTRY)\n",
    "    :param pub_url: url of the website providing the publication\n",
    "    \"\"\"\n",
    "    pub_type: str\n",
    "    bib_id: str\n",
    "    abstract: str\n",
    "    title: str\n",
    "    author: str\n",
    "    year: str # remember to change any other instances of pub_year to year\n",
    "    venue: str\n",
    "    journal: str\n",
    "    volume: str\n",
    "    number: str\n",
    "    pages: str\n",
    "    publisher: str\n",
    "    citation: str\n",
    "    url: str # place for journal article url to put in bib for zotero\n",
    "    extra: str # place for url_scholarbib to put in bib for zotero\n",
    "\n",
    "class Publication(TypedDict, total=False):\n",
    "    \"\"\"\n",
    "    :class:`Publication <Publication>` object used to represent a publication entry on Google Scholar.\n",
    "           (When source is not specified, the field is present in all sources)\n",
    "    :param BibEntryCitation: contains additional information about the publication\n",
    "    :param gsrank: position of the publication in the query (source: PUBLICATION_SEARCH_SNIPPET)\n",
    "    :param author_id: list of the corresponding author ids of the authors that contributed to the Publication (source: PUBLICATION_SEARCH_SNIPPET)\n",
    "    :param num_citations: number of citations of this Publication\n",
    "    :param cites_id: This corresponds to a \"single\" publication on Google Scholar. Used in the web search\n",
    "                       request to return all the papers that cite the publication. If cites_id =\n",
    "                       16766804411681372720 then:\n",
    "                       https://scholar.google.com/scholar?cites=<cites_id>&hl=en\n",
    "                       If the publication comes from a \"merged\" list of papers from an authors page,\n",
    "                       the \"citedby_id\" will be a comma-separated list of values.\n",
    "                       It is also used to return the \"cluster\" of all the different versions of the paper.\n",
    "                       https://scholar.google.com/scholar?cluster=16766804411681372720&hl=en\n",
    "                       (source: AUTHOR_PUBLICATION_ENTRY)\n",
    "    :param citedby_url: This corresponds to a \"single\" publication on Google Scholar. Used in the web search\n",
    "                       request to return all the papers that cite the publication.\n",
    "                       https://scholar.google.com/scholar?cites=16766804411681372720hl=en\n",
    "                       If the publication comes from a \"merged\" list of papers from an authors page,\n",
    "                       the \"citedby_url\" will be a comma-separated list of values.\n",
    "                       It is also used to return the \"cluster\" of all the different versions of the paper.\n",
    "                       https://scholar.google.com/scholar?cluster=16766804411681372720&hl=en\n",
    "    :param cites_per_year: a dictionay containing the number of citations per year for this Publication\n",
    "                           (source: AUTHOR_PUBLICATION_ENTRY)\n",
    "    :param eprint_url: digital version of the Publication. Usually it is a pdf.\n",
    "    :param pub_url: url of the website providing the publication\n",
    "    :param author_pub_id: The id of the paper on Google Scholar from an author page. Comes from the\n",
    "                          parameter \"citation_for_view=PA9La6oAAAAJ:YsMSGLbcyi4C\". It combines the\n",
    "                          author id, together with a publication id. It may corresponds to a merging\n",
    "                          of multiple publications, and therefore may have multiple \"citedby_id\"\n",
    "                          values.\n",
    "                          (source: AUTHOR_PUBLICATION_ENTRY)\n",
    "    :param public_access: Boolean corresponding to whether the article is available or not in accordance with public access mandates.\n",
    "    :param mandates: List of mandates with funding information and public access requirements.\n",
    "    :param url_related_articles: the url containing link for related articles of a publication (needs fill() for AUTHOR_PUBLICATION_ENTRIES)\n",
    "    :param url_add_sclib: (source: PUBLICATION_SEARCH_SNIPPET)\n",
    "    :param url_scholarbib: the url containing links for\n",
    "                           the BibTeX entry, EndNote, RefMan and RefWorks (source: PUBLICATION_SEARCH_SNIPPET)\n",
    "    :param filled: whether the publication is fully filled or not\n",
    "    :param source: The source of the publication entry\n",
    "    :param container_type: Used from the source code to identify if this container object\n",
    "                           is an Author or a Publication object.\n",
    "    \"\"\"\n",
    "\n",
    "    bib: BibEntry\n",
    "    gsrank: int\n",
    "    author_id: List[str]\n",
    "    num_citations: int\n",
    "    cites_id: List[str]\n",
    "    citedby_url: str\n",
    "    cites_per_year: CitesPerYear\n",
    "    author_pub_id: str\n",
    "    public_access: bool\n",
    "    mandates: List[Mandate]\n",
    "    eprint_url: str\n",
    "    pub_url: str\n",
    "    url_add_sclib: str\n",
    "    url_related_articles: str\n",
    "    url_scholarbib: str\n",
    "    filled: bool\n",
    "    source: PublicationSource\n",
    "    container_type: str\n",
    "\n",
    "class PublicationParser(object):\n",
    "    \"\"\"Returns an object for a single publication\"\"\"\n",
    "\n",
    "    def __init__(self, nav):\n",
    "        self.nav = nav\n",
    "\n",
    "    def get_publication(self, __data, pubtype: PublicationSource)->Publication:\n",
    "        \"\"\"Returns a publication that has either 'citation' or 'scholar' source\n",
    "        \"\"\"\n",
    "\n",
    "        publication: Publication = {'container_type': 'Publication'}\n",
    "        publication['source'] = pubtype\n",
    "        publication['bib'] = {}\n",
    "        publication['filled'] = False\n",
    "\n",
    "        if publication['source'] == PublicationSource.AUTHOR_PUBLICATION_ENTRY:\n",
    "            return self._citation_pub(__data, publication)\n",
    "        elif publication['source'] == PublicationSource.PUBLICATION_SEARCH_SNIPPET:\n",
    "            return self._scholar_pub(__data, publication)\n",
    "        elif publication['source'] == PublicationSource.JOURNAL_CITATION_LIST:\n",
    "            return publication\n",
    "            # TODO: self._journal_pub(__data, publication)\n",
    "        else:\n",
    "            return publication\n",
    "\n",
    "    def bibtex_entry_maker(self, publication: Publication) -> str:\n",
    "        \"\"\"Returns the publication as a Bibtex entry\n",
    "        :param publication: Scholar or Citation publication container object\n",
    "        :type publication: Publication\n",
    "        :getter: Returns a Bibtex entry in text format\n",
    "        :type: str\n",
    "        \"\"\"\n",
    "        # if not publication['filled']:\n",
    "        #     publication = self.fill(publication)\n",
    "        bibdb = BibDatabase()\n",
    "        converted_dict = publication['bib']\n",
    "        converted_dict = remap_bib(converted_dict, _BIB_REVERSE_MAPPING)\n",
    "        str_dict = {key: str(value) for key, value in converted_dict.items()}\n",
    "        # convert every key of the dictionary to string to be Bibtex compatible\n",
    "        bibdb.entries = [str_dict]\n",
    "        return bibtexparser.dumps(bibdb)\n",
    "\n",
    "    def _get_bibtex_url(self, bib_url) -> str:\n",
    "        \"\"\"Retrieves the bibtex url\"\"\"\n",
    "\n",
    "        soup = self.nav._get_soup(bib_url)\n",
    "        styles = soup.find_all('a', class_='gs_citi')\n",
    "\n",
    "        for link in styles:\n",
    "            if link.string.lower() == \"bibtex\":\n",
    "                return link.get('href')\n",
    "        return ''\n",
    "\n",
    "    # def _scholar_pub(self, __data, publication: Publication):\n",
    "    #     title = __data['title']\n",
    "\n",
    "    #     cid = __data.get('data-cid')\n",
    "    #     pos = __data.get('data-rp')\n",
    "\n",
    "    #     publication['gsrank'] = int(pos) + 1\n",
    "\n",
    "    #     if title.find('span', class_='gs_ctu'):  # A citation\n",
    "    #         title.span.extract()\n",
    "    #     elif title.find('span', class_='gs_ctc'):  # A book or PDF\n",
    "    #         title.span.extract()\n",
    "\n",
    "    #     publication['bib']['title'] = title.text.strip()\n",
    "\n",
    "    #     if title.find('a'):\n",
    "    #         publication['pub_url'] = title.find('a')['href']\n",
    "\n",
    "    #     author_div_element = databox.find('div', class_='gs_a')\n",
    "    #     authorinfo = author_div_element.text\n",
    "    #     authorinfo = authorinfo.replace(u'\\xa0', u' ')       # NBSP\n",
    "    #     authorinfo = authorinfo.replace(u'&amp;', u'&')      # Ampersand\n",
    "    #     publication['bib'][\"author\"] = self._get_authorlist(authorinfo)\n",
    "    #     authorinfo_html = author_div_element.decode_contents()\n",
    "    #     publication[\"author_id\"] = self._get_author_id_list(authorinfo_html)\n",
    "\n",
    "    #     # There are 4 (known) patterns in the author/venue/year/host line:\n",
    "    #     #  (A) authors - host\n",
    "    #     #  (B) authors - venue, year - host\n",
    "    #     #  (C) authors - venue - host\n",
    "    #     #  (D) authors - year - host\n",
    "    #     # The authors are handled above so below is only concerned with\n",
    "    #     # the middle venue/year part. In principle the venue is separated\n",
    "    #     # from the year by a comma. However, there exist venues with commas\n",
    "    #     # and as shown above there might not always be a venue AND a year...\n",
    "    #     venueyear = authorinfo.split(' - ')\n",
    "    #     # If there is no middle part (A) then venue and year are unknown.\n",
    "    #     if len(venueyear) <= 2:\n",
    "    #         publication['bib']['venue'], publication['bib']['pub_year'] = 'NA', 'NA'\n",
    "    #     else:\n",
    "    #         venueyear = venueyear[1].split(',')\n",
    "    #         venue = 'NA'\n",
    "    #         year = venueyear[-1].strip()\n",
    "    #         if year.isnumeric() and len(year) == 4:\n",
    "    #             publication['bib']['pub_year'] = year\n",
    "    #             if len(venueyear) >= 2:\n",
    "    #                 venue = ','.join(venueyear[0:-1]) # everything but last\n",
    "    #         else:\n",
    "    #             venue = ','.join(venueyear) # everything\n",
    "    #             publication['bib']['pub_year'] = 'NA'\n",
    "    #         publication['bib']['venue'] = venue\n",
    "\n",
    "    #     if databox.find('div', class_='gs_rs'):\n",
    "    #         publication['bib']['abstract'] = databox.find('div', class_='gs_rs').text\n",
    "    #         publication['bib']['abstract'] = publication['bib']['abstract'].replace(u'\\u2026', u'')\n",
    "    #         publication['bib']['abstract'] = publication['bib']['abstract'].replace(u'\\n', u' ')\n",
    "    #         publication['bib']['abstract'] = publication['bib']['abstract'].strip()\n",
    "\n",
    "    #         if publication['bib']['abstract'][0:8].lower() == 'abstract':\n",
    "    #             publication['bib']['abstract'] = publication['bib']['abstract'][9:].strip()\n",
    "\n",
    "    #     publication['url_scholarbib'] = _BIBCITE.format(cid, pos)\n",
    "    #     sclib = self.nav.publib.format(id=cid)\n",
    "    #     publication['url_add_sclib'] = sclib\n",
    "\n",
    "    #     lowerlinks = databox.find('div', class_='gs_fl').find_all('a')\n",
    "\n",
    "    #     publication[\"num_citations\"] = 0\n",
    "\n",
    "    #     for link in lowerlinks:\n",
    "    #         if 'Cited by' in link.text:\n",
    "    #             publication['num_citations'] = int(re.findall(r'\\d+', link.text)[0].strip())\n",
    "    #             publication['citedby_url'] = link['href']\n",
    "\n",
    "    #         if 'Related articles' in link.text:\n",
    "    #             publication['url_related_articles'] = link['href']\n",
    "\n",
    "    #     if __data.find('div', class_='gs_ggs gs_fl'):\n",
    "    #         publication['eprint_url'] = __data.find(\n",
    "    #             'div', class_='gs_ggs gs_fl').a['href']\n",
    "    #     return publication\n",
    "\n",
    "\n",
    "class _SearchScholarIterator(object):\n",
    "    \"\"\"Iterator that returns Publication objects from the search page\n",
    "    I have removed all logging from here for simplicity. -V\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nav, url: str):\n",
    "        self._url = url\n",
    "        self._pubtype = PublicationSource.PUBLICATION_SEARCH_SNIPPET if \"/scholar?\" in url else PublicationSource.JOURNAL_CITATION_LIST\n",
    "        self._nav = nav\n",
    "        self._load_url(url)\n",
    "        self.total_results = self._get_total_results()\n",
    "        self.pub_parser = PublicationParser(self._nav)\n",
    "\n",
    "    def _load_url(self, url: str):\n",
    "        # this is temporary until setup json file\n",
    "        self._soup = self._nav._get_soup(url)\n",
    "        self._pos = 0\n",
    "        self._rows = self._soup.find_all('div', class_='gs_r gs_or gs_scl') + self._soup.find_all('div', class_='gsc_mpat_ttl')\n",
    "\n",
    "    # Iterator protocol\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._pos < len(self._rows):\n",
    "            row = self._rows[self._pos]\n",
    "            self._pos += 1\n",
    "            res = self.pub_parser.get_publication(row, self._pubtype)\n",
    "            return res\n",
    "        elif self._soup.find(class_='gs_ico gs_ico_nav_next'):\n",
    "            url = self._soup.find(\n",
    "                class_='gs_ico gs_ico_nav_next').parent['href']\n",
    "            self._url = url\n",
    "            self._load_url(url)\n",
    "            return self.__next__()\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "    # Pickle protocol\n",
    "    def __getstate__(self):\n",
    "        return {'url': self._url, 'pos': self._pos}\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        # this needs validation -V\n",
    "        self._load_url(state['url'])\n",
    "        self._pos = state['pos']\n",
    "\n",
    "# FUNCTIONS BELOW HERE\n",
    "\n",
    "def remap_bib(parsed_bib: dict, mapping: dict, data_types:dict ={}) -> BibEntry:\n",
    "    for key, value in mapping.items():\n",
    "        if key in parsed_bib:\n",
    "            parsed_bib[value] = parsed_bib.pop(key)\n",
    "\n",
    "    for key, value in data_types.items():\n",
    "        if key in parsed_bib:\n",
    "            if value == 'int':\n",
    "                parsed_bib[key] = int(parsed_bib[key])\n",
    "\n",
    "    return parsed_bib\n",
    "\n",
    "\n",
    "\n",
    "# I think I can call this function on each item in the array\n",
    "\n",
    "_AUTHSEARCH = '/citations?hl=en&view_op=search_authors&mauthors={0}'\n",
    "_KEYWORDSEARCH = '/citations?hl=en&view_op=search_authors&mauthors=label:{0}'\n",
    "_KEYWORDSEARCHBASE = '/citations?hl=en&view_op=search_authors&mauthors={}'\n",
    "_PUBSEARCH = '/scholar?hl=en&num=20&q={0}'\n",
    "_CITEDBYSEARCH = '/scholar?hl=en&num=20&cites={0}'\n",
    "_ORGSEARCH = \"/citations?view_op=view_org&hl=en&org={0}\"\n",
    "_MANDATES_URL = \"https://scholar.google.com/citations?view_op=mandates_leaderboard_csv&hl=en\"\n",
    "\n",
    "class _Scholarly:\n",
    "    \"\"\"Class that manages the API for scholarly\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # load_dotenv(find_dotenv())\n",
    "        # self.env = os.environ.copy()\n",
    "        # self.__nav = Navigator()\n",
    "        # self.logger = self.__nav.logger\n",
    "        # self._journal_categories = None\n",
    "        self.test = 'some test info'\n",
    "\n",
    "    def bibtex(self, object: Publication)->str:\n",
    "        \"\"\"Returns a bibtex entry for a publication that has either Scholar source\n",
    "        or citation source\n",
    "        :param object: The Publication object for the bibtex exportation\n",
    "        :type object: Publication\n",
    "        \"\"\"\n",
    "        if object['container_type'] == \"Publication\":\n",
    "            publication_parser = PublicationParser(self.__nav)\n",
    "            return publication_parser.bibtex_entry_maker(object)\n",
    "        else:\n",
    "            self.logger.warning(\"Object not supported for bibtex exportation\")\n",
    "            return\n",
    "        \n",
    "    def search_pubs(self,\n",
    "                    query: str, patents: bool = True,\n",
    "                    citations: bool = True, year_low: int = None,\n",
    "                    year_high: int = None, sort_by: str = \"relevance\",\n",
    "                    include_last_year: str = \"abstracts\",\n",
    "                    start_index: int = 0)->_SearchScholarIterator:\n",
    "        \"\"\"Searches by query and returns a generator of Publication objects\n",
    "        :param query: terms to be searched\n",
    "        :type query: str\n",
    "        :param patents: Whether or not to include patents, defaults to True\n",
    "        :type patents: bool, optional\n",
    "        :param citations: Whether or not to include citations, defaults to True\n",
    "        :type citations: bool, optional\n",
    "        :param year_low: minimum year of publication, defaults to None\n",
    "        :type year_low: int, optional\n",
    "        :param year_high: maximum year of publication, defaults to None\n",
    "        :type year_high: int, optional\n",
    "        :param sort_by: 'relevance' or 'date', defaults to 'relevance'\n",
    "        :type sort_by: string, optional\n",
    "        :param include_last_year: 'abstracts' or 'everything', defaults to 'abstracts' and only applies if 'sort_by' is 'date'\n",
    "        :type include_last_year: string, optional\n",
    "        :param start_index: starting index of list of publications, defaults to 0\n",
    "        :type start_index: int, optional\n",
    "        :returns: Generator of Publication objects\n",
    "        :rtype: Iterator[:class:`Publication`]\n",
    "        :Example::\n",
    "        .. testcode::\n",
    "            search_query = scholarly.search_pubs('Perception of physical stability and center of mass of 3D objects')\n",
    "            scholarly.pprint(next(search_query)) # in order to pretty print the result\n",
    "        :Output::\n",
    "        .. testoutput::\n",
    "            {'author_id': ['4bahYMkAAAAJ', 'ruUKktgAAAAJ', ''],\n",
    "             'bib': {'abstract': 'Humans can judge from vision alone whether an object is '\n",
    "                                 'physically stable or not. Such judgments allow observers '\n",
    "                                 'to predict the physical behavior of objects, and hence '\n",
    "                                 'to guide their motor actions. We investigated the visual '\n",
    "                                 'estimation of physical stability of 3-D objects (shown '\n",
    "                                 'in stereoscopically viewed rendered scenes) and how it '\n",
    "                                 'relates to visual estimates of their center of mass '\n",
    "                                 '(COM). In Experiment 1, observers viewed an object near '\n",
    "                                 'the edge of a table and adjusted its tilt to the '\n",
    "                                 'perceived critical angle, ie, the tilt angle at which '\n",
    "                                 'the object',\n",
    "                     'author': ['SA Cholewiak', 'RW Fleming', 'M Singh'],\n",
    "                     'pub_year': '2015',\n",
    "                     'title': 'Perception of physical stability and center of mass of 3-D '\n",
    "                              'objects',\n",
    "                     'venue': 'Journal of vision'},\n",
    "             'citedby_url': '/scholar?cites=15736880631888070187&as_sdt=5,33&sciodt=0,33&hl=en',\n",
    "             'eprint_url': 'https://jov.arvojournals.org/article.aspx?articleID=2213254',\n",
    "             'filled': False,\n",
    "             'gsrank': 1,\n",
    "             'num_citations': 23,\n",
    "             'pub_url': 'https://jov.arvojournals.org/article.aspx?articleID=2213254',\n",
    "             'source': 'PUBLICATION_SEARCH_SNIPPET',\n",
    "             'url_add_sclib': '/citations?hl=en&xsrf=&continue=/scholar%3Fq%3DPerception%2Bof%2Bphysical%2Bstability%2Band%2Bcenter%2Bof%2Bmass%2Bof%2B3D%2Bobjects%26hl%3Den%26as_sdt%3D0,33&citilm=1&json=&update_op=library_add&info=K8ZpoI6hZNoJ&ei=QhqhX66wKoyNy9YPociEuA0',\n",
    "             'url_scholarbib': '/scholar?q=info:K8ZpoI6hZNoJ:scholar.google.com/&output=cite&scirp=0&hl=en'}\n",
    "        \"\"\"\n",
    "        url = self._construct_url(_PUBSEARCH.format(requests.utils.quote(query)), patents=patents,\n",
    "                                  citations=citations, year_low=year_low, year_high=year_high,\n",
    "                                  sort_by=sort_by, include_last_year=include_last_year, start_index=start_index)\n",
    "        return self.__nav.search_publications(url)\n",
    "\n",
    "# Trying NOT to load the JSON file and make it into a searchscholariterator object.\n",
    "\n",
    "scholarly = _Scholarly()\n",
    "# get_pub = get_publication(self, __data, pubtype: PublicationSource)->Publication:\n",
    "# get_pub = get_publication(self, __data, pubtype: PublicationSource)->Publication:\n",
    "\n",
    "for pubitem in test_array:\n",
    "    print(_Scholarly.bibtex())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "812f74ffa169d7186919aad1b064e1de01ac83f7d294665c43dd347688936873"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
